{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6a47162",
   "metadata": {},
   "source": [
    "### Wetland delineation  \n",
    "This notebook outlines the workflow for wetland delineation using data derived from GEE and applying Random classification model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aaa3555",
   "metadata": {},
   "source": [
    "#### 1. Initial setup and GEE connection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a6e212",
   "metadata": {},
   "source": [
    "#### 1.1 Install and import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3c92648",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import os\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio     \n",
    "import numpy as np  \n",
    "\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f80046f",
   "metadata": {},
   "source": [
    "#### 1.2. Connect to GEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c11ad5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate and initialize Earth Engine\n",
    "ee.Authenticate()\n",
    "ee.Initialize(project=\"ee-ogalloethel\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6619166e",
   "metadata": {},
   "source": [
    "#### 1.3. Define AOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d25f3f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base directory found: C:\\Users\\Ethel Ogallo\\Documents\\ZFL1\\Data\n"
     ]
    }
   ],
   "source": [
    "# Base directory whee data is stored\n",
    "base_dir = r\"C:\\Users\\Ethel Ogallo\\Documents\\ZFL1\\Data\"\n",
    "\n",
    "# Verify the directory exists\n",
    "if not os.path.exists(base_dir):\n",
    "    print(f\"WARNING: Base directory does not exist: {base_dir}\\nPlease check your path!\")\n",
    "else:\n",
    "    print(f\"Base directory found: {base_dir}\")\n",
    "\n",
    "# Set AOI from shapefile\n",
    "shapefile = gpd.read_file(os.path.join(base_dir, 'baringo_bbox/baringo_bbox.shp'))\n",
    "study_area = ee.Geometry(shapefile.geometry[0].__geo_interface__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4ea75f",
   "metadata": {},
   "source": [
    "#### 2. Downloading data from GEE  \n",
    "The necessary EO data downloaded include: DEM and slope, Land surface temperature, Derived NDVI and NDWI, Sentinel1-GRD data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e033a2",
   "metadata": {},
   "source": [
    "#### 2.1 Generic functions to export GEE data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad366c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read a raster file and return an aligned array\n",
    "def clip_to_aoi(image):\n",
    "    \"\"\"\n",
    "    Clip an ee.Image to the study_area geometry.\n",
    "    Args:\n",
    "        image (ee.Image): The image to clip.\n",
    "    Returns:   \n",
    "        ee.Image: The clipped image.\n",
    "        \"\"\"\n",
    "    if not isinstance(image, ee.Image):\n",
    "        raise TypeError(\"Input must be an ee.Image\")\n",
    "    return image.clip(study_area)\n",
    "\n",
    "# Function to export an ee.Image to Google Drive\n",
    "def export_image_to_drive(image, year, label='image', folder='Exports', scale=30):\n",
    "    \"\"\"\n",
    "    Export an ee.Image to Google Drive.\n",
    "    Args:\n",
    "        image (ee.Image): The image to export.\n",
    "        year (int): The year associated with the image.\n",
    "        label (str): A label for the exported image.\n",
    "        folder (str): The folder in Google Drive to save the image.\n",
    "        scale (int): The scale of the exported image in meters.\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    task = ee.batch.Export.image.toDrive(\n",
    "        image=image,\n",
    "        description=f'{label}_{year}',\n",
    "        folder=folder,\n",
    "        fileNamePrefix=f'{label}_{year}',\n",
    "        scale=scale,\n",
    "        region=study_area,\n",
    "        fileFormat='GeoTIFF',\n",
    "        maxPixels=1e13\n",
    "    )\n",
    "    task.start()\n",
    "    print(f\"Export started: {label}_{year}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c00164",
   "metadata": {},
   "source": [
    "#### 2.1. Download DEM and SLope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9334f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get DEM and slope\n",
    "def get_dem():\n",
    "    \"\"\"\n",
    "    Retrieve DEM and slope.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[ee.Image, ee.Image]: (DEM image, slope image)\n",
    "    \"\"\"\n",
    "    dem = ee.ImageCollection(\"COPERNICUS/DEM/GLO30\") \\\n",
    "        .filterBounds(study_area).mosaic().select('DEM')\n",
    "    dem = clip_to_aoi(dem).toFloat().reproject('EPSG:32736', 30)\n",
    "    slope = ee.Terrain.slope(dem).rename('Slope')\n",
    "    return dem.rename('DEM'), slope\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dead930b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get DEM and slope\n",
    "dem, slope = get_dem()\n",
    "\n",
    "# Export or process each as needed\n",
    "export_image_to_drive(dem, year='DEM', label='DEM', folder='DEM')\n",
    "export_image_to_drive(slope, year='Slope', label='Slope', folder='DEM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ecff75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to reproject a raster to match another raster's CRS and dimensions\n",
    "def reproject_to_match(src_path, ref_path, dst_path):\n",
    "    \"\"\"\n",
    "    Reproject a raster to match the CRS, transform, and shape of a reference raster.\n",
    "    Args:\n",
    "        src_path (str): Path to source raster.\n",
    "        ref_path (str): Path to reference raster.\n",
    "        dst_path (str): Path to save reprojected raster.\n",
    "    \"\"\"\n",
    "    with rasterio.open(ref_path) as ref, rasterio.open(src_path) as src:\n",
    "        dst_array = np.empty((ref.height, ref.width), dtype=src.dtypes[0])\n",
    "        reproject(\n",
    "            source=src.read(1),\n",
    "            destination=dst_array,\n",
    "            src_transform=src.transform,\n",
    "            src_crs=src.crs,\n",
    "            dst_transform=ref.transform,\n",
    "            dst_crs=ref.crs,\n",
    "            resampling=Resampling.bilinear\n",
    "        )\n",
    "        profile = src.profile.copy()\n",
    "        profile.update({\n",
    "            'crs': ref.crs,\n",
    "            'transform': ref.transform,\n",
    "            'width': ref.width,\n",
    "            'height': ref.height\n",
    "        })\n",
    "        with rasterio.open(dst_path, 'w', **profile) as dst:\n",
    "            dst.write(dst_array, 1)\n",
    "\n",
    "# Usage example:\n",
    "reproject_to_match(\n",
    "    src_path=os.path.join(base_dir, 'DEM', 'Slope.tif'),\n",
    "    ref_path=os.path.join(base_dir, 'DEM', 'DEM.tif'),\n",
    "    dst_path=os.path.join(base_dir, 'DEM', 'Slope_aligned.tif')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c7845e",
   "metadata": {},
   "source": [
    "#### 2.2. Download Landsat Land Surface Temperature (LST) 2015-2025\n",
    "A cloud mask was appled prior to download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502a3799",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cloud_mask(image):\n",
    "    # Mask clouds and cloud shadows using QA_PIXEL band\n",
    "    qa = image.select('QA_PIXEL')\n",
    "    mask = qa.bitwiseAnd(1 << 3).eq(0).And(qa.bitwiseAnd(1 << 5).eq(0))\n",
    "    return image.updateMask(mask)\n",
    "\n",
    "def download_lst(year):\n",
    "    \"\"\"\n",
    "    Download Landsat 8 LST for a specific year.\n",
    "    Args:\n",
    "        year (int): The year for which to download the LST image.\n",
    "    Returns:\n",
    "        ee.Image: The mean LST image for the specified year.\n",
    "    \"\"\"\n",
    "    lst_col = (ee.ImageCollection('LANDSAT/LC08/C02/T1_L2')\n",
    "               .filterBounds(study_area)\n",
    "               .filterDate(f'{year}-01-01', f'{year}-12-31')\n",
    "               .map(cloud_mask)\n",
    "               .map(lambda img: img.select('ST_B10')\n",
    "                    .multiply(0.00341802).add(149.0)\n",
    "                    .subtract(273.15)\n",
    "                    .rename('LST'))\n",
    "               .map(clip_to_aoi))\n",
    "    return lst_col.mean().set({'year': year})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251ff397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the years and export LST images\n",
    "years = list(range(2015, 2026))\n",
    "\n",
    "# Get the LST image for each year and export it to Google Drive\n",
    "for year in years: \n",
    "    lst = download_lst(year)\n",
    "    export_image_to_drive(lst, year, label='LST_mean', folder='LST')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2d70aa",
   "metadata": {},
   "source": [
    "#### 2.3. Compute NDVI Standard Deviation and Oscillation 2015-2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c6f063",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ndvi(year):\n",
    "    \"\"\"\n",
    "    Compute NDVI for Sentinel-2 images for a specific year.\n",
    "    Args:\n",
    "        year (int): The year for which to compute NDVI.\n",
    "    Returns:   \n",
    "        ee.Image: The NDVI standard deviation and range for the specified year.\n",
    "    \"\"\"\n",
    "    s2 = (ee.ImageCollection('COPERNICUS/S2_HARMONIZED')\n",
    "          .filterBounds(study_area)\n",
    "          .filterDate(f'{year}-01-01', f'{year}-12-31')\n",
    "          .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 10))\n",
    "          .map(clip_to_aoi)\n",
    "          .map(lambda img: img.addBands(\n",
    "              img.normalizedDifference(['B8', 'B4']).rename('NDVI')))\n",
    "          .select('NDVI'))\n",
    "\n",
    "    ndvi_std = s2.reduce(ee.Reducer.stdDev()).rename(f'NDVI_SD_{year}')\n",
    "    ndvi_range = s2.reduce(ee.Reducer.max()).subtract(\n",
    "        s2.reduce(ee.Reducer.min())\n",
    "    ).rename(f'NDVI_Range_{year}')\n",
    "    return ndvi_std, ndvi_range\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2d7fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export NDVI statistics to Google Drive\n",
    "for year in years:\n",
    "    ndvi_std, ndvi_range = compute_ndvi(year)\n",
    "    export_image_to_drive(ndvi_std, year, label='NDVI_SD', folder='NDVI')\n",
    "    export_image_to_drive(ndvi_range, year, label='NDVI_Range', folder='NDVI')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822fb727",
   "metadata": {},
   "source": [
    "#### 2.4. Compute max NDWI from S2 2015-2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da19e139",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ndwi(year):\n",
    "    \"\"\"\n",
    "    Compute maximum NDWI for Sentinel-2 images for a given year.\n",
    "    Args:\n",
    "        year (int): Year of interest.\n",
    "    Returns:\n",
    "        ee.Image: Max NDWI image.\n",
    "    \"\"\"\n",
    "    s2 = (ee.ImageCollection('COPERNICUS/S2_HARMONIZED')\n",
    "          .filterBounds(study_area)\n",
    "          .filterDate(f'{year}-01-01', f'{year}-12-31')\n",
    "          .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 10))\n",
    "          .map(clip_to_aoi)\n",
    "          .map(lambda img: img.normalizedDifference(['B8', 'B3'])\n",
    "               .rename('NDWI').toFloat()))\n",
    "    return s2.max().rename(f'NDWI_Max_{year}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace1f5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export NDVI statistics \n",
    "for year in years:\n",
    "    ndwi_max = compute_ndwi(year)\n",
    "    export_image_to_drive(ndwi_max, year, label='NDWI_Max', folder='NDWI')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b64580e",
   "metadata": {},
   "source": [
    "#### 2.5 Download S1 VV and VH GRD from 2015-2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35bfeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentinel1_min(year, pol='VV', orbit_pass='ASCENDING'):\n",
    "    \"\"\"\n",
    "    Get annual minimum Sentinel-1 backscatter (dB) for given polarization.\n",
    "\n",
    "    Args:\n",
    "        year (int): Year of interest.\n",
    "        pol (str): Polarization ('VV' or 'VH').\n",
    "        orbit_pass (str): Orbit pass ('ASCENDING' or 'DESCENDING').\n",
    "    Returns:\n",
    "        ee.Image: Minimum Sentinel-1 backscatter image for the specified year and polarization.\n",
    "    \"\"\"\n",
    "    s1 = (ee.ImageCollection('COPERNICUS/S1_GRD')\n",
    "          .filterDate(f'{year}-01-01', f'{year}-12-31')\n",
    "          .filterBounds(study_area)\n",
    "          .filter(ee.Filter.eq('instrumentMode', 'IW'))\n",
    "          .filter(ee.Filter.eq('orbitProperties_pass', orbit_pass))\n",
    "          .filter(ee.Filter.eq('resolution_meters', 10))\n",
    "          .filter(ee.Filter.listContains('transmitterReceiverPolarisation', pol))\n",
    "          .select(pol))\n",
    "    return clip_to_aoi(s1.min().rename(f'S1_{pol}_Min_{year}'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222dc7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export Sentinel-1 VV and VH minimum backscatter images for each year\n",
    "for year in years:\n",
    "    for pol in ['VV', 'VH']:\n",
    "        img = get_sentinel1_min(year, pol=pol)\n",
    "        task = ee.batch.Export.image.toDrive(\n",
    "            image=img,\n",
    "            description=f'S1_{pol}_Min_{year}',\n",
    "            folder=f'S1_{pol}',\n",
    "            fileNamePrefix=f'S1_{pol}_Min_{year}',\n",
    "            region=study_area,\n",
    "            scale=10,\n",
    "            crs='EPSG:4326',\n",
    "            maxPixels=1e13\n",
    "        )\n",
    "        task.start()\n",
    "        print(f\"Started export: S1_{pol}_Min_{year}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84c3668",
   "metadata": {},
   "source": [
    "### 4. Feature clasification using Random Forest  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d59c13ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from rasterio.io import MemoryFile\n",
    "from rasterio.transform import rowcol, from_bounds\n",
    "from rasterio.features import geometry_mask\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "from skimage.morphology import opening, square\n",
    "from scipy.interpolate import griddata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6783a85",
   "metadata": {},
   "source": [
    "#### 4.1 Training points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c10bccf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed extent: (35.9167, 0.3, 36.216699999999996, 0.8999999999999999)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>water</td>\n",
       "      <td>POINT (36.06711 0.56802)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>water</td>\n",
       "      <td>POINT (36.04937 0.67043)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>water</td>\n",
       "      <td>POINT (36.09725 0.47869)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>water</td>\n",
       "      <td>POINT (36.09869 0.47104)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>water</td>\n",
       "      <td>POINT (36.07187 0.34713)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  class                  geometry\n",
       "0   1  water  POINT (36.06711 0.56802)\n",
       "1   2  water  POINT (36.04937 0.67043)\n",
       "2   3  water  POINT (36.09725 0.47869)\n",
       "3   4  water  POINT (36.09869 0.47104)\n",
       "4   5  water  POINT (36.07187 0.34713)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define AOI extents\n",
    "# Central point in decimal degrees\n",
    "center_lat = 0.6\n",
    "center_lon = 36.0667\n",
    "\n",
    "# Define a bounding box: ±0.3° latitude (north-south), ±0.15° longitude (east-west)\n",
    "lat_buffer = 0.3\n",
    "lon_buffer = 0.15\n",
    "\n",
    "# Compute extent (bounding box)\n",
    "extent = (\n",
    "    center_lon - lon_buffer,  # xmin (left)\n",
    "    center_lat - lat_buffer,  # ymin (bottom)\n",
    "    center_lon + lon_buffer,  # xmax (right)\n",
    "    center_lat + lat_buffer   # ymax (top)\n",
    ")\n",
    "\n",
    "print(\"Computed extent:\", extent)\n",
    "\n",
    "# Load training points and reproject to match LST raster CRS if needed\n",
    "gdf = gpd.read_file(os.path.join(base_dir, 'baringo_training_points.shp'))\n",
    "with rasterio.open(os.path.join(base_dir, \"DEM\", \"dem.tif\")) as src:\n",
    "    dem_crs = src.crs\n",
    "if gdf.crs != dem_crs:\n",
    "    gdf = gdf.to_crs(dem_crs)\n",
    "\n",
    "gdf.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a14d755",
   "metadata": {},
   "source": [
    "#### 4.2 Stacking all the raster data  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c08deb6",
   "metadata": {},
   "source": [
    "Ensure all data are of the same shape before attempting to stack  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "212f0bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raster shapes for year 2020:\n",
      "LST: (2887, 3209)\n",
      "NDWI: (2887, 3209)\n",
      "NDVI_SD: (2887, 3209)\n",
      "NDVI_range: (2887, 3209)\n",
      "VV: (8660, 9625)\n",
      "VH: (8660, 9625)\n"
     ]
    }
   ],
   "source": [
    "year = 2020\n",
    "\n",
    "file_map = {\n",
    "    \"LST\": os.path.join(base_dir, \"LST\", f\"LST_mean_{year}.tif\"),\n",
    "    \"NDWI\": os.path.join(base_dir, \"NDWI_1\", f\"NDWI_Max_{year}.tif\"),\n",
    "    \"NDVI_SD\": os.path.join(base_dir, \"NDVI\", f\"NDVI_SD_{year}.tif\"),\n",
    "    \"NDVI_range\": os.path.join(base_dir, \"NDVI\", f\"NDVI_Range_{year}.tif\"),\n",
    "    \"VV\": os.path.join(base_dir, \"S1_VV\", f\"S1_VV_Min_{year}.tif\"),\n",
    "    \"VH\": os.path.join(base_dir, \"S1_VH\", f\"S1_VH_Min_{year}.tif\"),\n",
    "}\n",
    "\n",
    "print(f\"Raster shapes for year {year}:\")\n",
    "for name, path in file_map.items():\n",
    "    if os.path.exists(path):\n",
    "        with rasterio.open(path) as src:\n",
    "            print(f\"{name}: {src.shape}\")\n",
    "    else:\n",
    "        print(f\"{name}: MISSING ({path})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3b97b3",
   "metadata": {},
   "source": [
    "Cropping the raster data to the defined extents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cf144c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbeb4e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasterio.windows import from_bounds\n",
    "\n",
    "# DEM and slope (static)\n",
    "dem_path = os.path.join(base_dir, \"DEM\", \"DEM.tif\")\n",
    "slope_path = os.path.join(base_dir, \"DEM\", \"Slope_aligned.tif\")\n",
    "\n",
    "# Prepare output dictionary\n",
    "cropped_rasters_by_year = {}\n",
    "\n",
    "for year in range(2015, 2026):\n",
    "    year_data = {}\n",
    "\n",
    "    # Temporal rasters \n",
    "    file_map = {\n",
    "        \"LST\": os.path.join(base_dir, \"LST\", f\"LST_mean_{year}.tif\"),\n",
    "        \"NDWI\": os.path.join(base_dir, \"NDWI_1\", f\"NDWI_Max_{year}.tif\"),\n",
    "        \"NDVI_SD\": os.path.join(base_dir, \"NDVI\", f\"NDVI_SD_{year}.tif\"),\n",
    "        \"NDVI_range\": os.path.join(base_dir, \"NDVI\", f\"NDVI_Range_{year}.tif\"),\n",
    "        \"VV\": os.path.join(base_dir, \"S1_VV\", f\"S1_VV_Min_{year}.tif\"),\n",
    "        \"VH\": os.path.join(base_dir, \"S1_VH\", f\"S1_VH_Min_{year}.tif\"),\n",
    "    }\n",
    "\n",
    "    for name, path in file_map.items():\n",
    "        if not os.path.exists(path):\n",
    "            print(f\"Missing: {path}\")\n",
    "            continue\n",
    "        with rasterio.open(path) as src:\n",
    "            window = from_bounds(*extent, transform=src.transform)\n",
    "            arr = src.read(1, window=window)\n",
    "            year_data[name] = arr\n",
    "\n",
    "    # Static rasters \n",
    "    for path, name in zip([dem_path, slope_path], [\"DEM\", \"Slope\"]):\n",
    "        with rasterio.open(path) as src:\n",
    "            window = from_bounds(*extent, transform=src.transform)\n",
    "            arr = src.read(1, window=window)\n",
    "            year_data[name] = arr\n",
    "\n",
    "\n",
    "    # Save year if at least some data exists\n",
    "    if len(year_data) > 0:\n",
    "        cropped_rasters_by_year[year] = year_data\n",
    "    else:\n",
    "        print(f\"No data stored for {year}\")\n",
    "\n",
    "print(\"Cropping complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51f74b8",
   "metadata": {},
   "source": [
    "resampling vv and vh to the same shape to match the rest of the rasters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6921df58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_to_ref(src_arr, src_path, dst_shape, dst_transform, dst_crs):\n",
    "    with rasterio.open(src_path) as src:\n",
    "        src_transform = src.window_transform(\n",
    "            from_bounds(*extent, transform=src.transform)\n",
    "        )\n",
    "        src_crs = src.crs\n",
    "        dst_arr = np.empty(dst_shape, dtype=src_arr.dtype)\n",
    "\n",
    "        reproject(\n",
    "            source=src_arr,\n",
    "            destination=dst_arr,\n",
    "            src_transform=src_transform,\n",
    "            src_crs=src_crs,\n",
    "            dst_transform=dst_transform,\n",
    "            dst_crs=dst_crs,\n",
    "            resampling=Resampling.bilinear,\n",
    "        )\n",
    "    return dst_arr\n",
    "\n",
    "\n",
    "# Reference raster info (DEM)\n",
    "with rasterio.open(dem_path) as dem_src:\n",
    "    window = from_bounds(*extent, transform=dem_src.transform)\n",
    "    dem_transform = dem_src.window_transform(window)\n",
    "    dem_crs = dem_src.crs\n",
    "\n",
    "for year in cropped_rasters_by_year:\n",
    "    dem_arr = cropped_rasters_by_year[year][\"DEM\"]\n",
    "    dst_shape = dem_arr.shape\n",
    "\n",
    "    for pol in [\"VV\", \"VH\"]:\n",
    "        if pol in cropped_rasters_by_year[year]:\n",
    "            src_arr = cropped_rasters_by_year[year][pol]\n",
    "            src_path = os.path.join(base_dir, f\"S1_{pol}\", f\"S1_{pol}_Min_{year}.tif\")\n",
    "\n",
    "            resampled_arr = resample_to_ref(src_arr, src_path, dst_shape, dem_transform, dem_crs)\n",
    "            cropped_rasters_by_year[year][pol] = resampled_arr\n",
    "\n",
    "print(\"Resampling VV/VH complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494cde2c",
   "metadata": {},
   "source": [
    "Visualizzing th erasters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fc6f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_data = cropped_rasters_by_year[2020]\n",
    "\n",
    "layers_to_plot = [\"DEM\", \"Slope\", \"LST\", \"NDWI\", \"NDVI_SD\", \"NDVI_range\", \"VV\", \"VH\"]\n",
    "colormaps = {\n",
    "    \"DEM\": \"terrain\", \"Slope\": \"inferno\", \"LST\": \"plasma\", \"NDWI\": \"Blues\",\n",
    "    \"NDVI_SD\": \"BuGn\", \"NDVI_range\": \"BuGn\", \"VV\": \"Greys\", \"VH\": \"Greys\"\n",
    "}\n",
    "\n",
    "nrows = 2\n",
    "ncols = -(-len(layers_to_plot) // nrows)  # ceiling division \n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(4 * ncols, 5 * nrows))\n",
    "axes = axes.flatten()\n",
    "xmin, ymin, xmax, ymax = extent\n",
    "\n",
    "for ax, name in zip(axes, layers_to_plot):\n",
    "    if name in layer_data:\n",
    "        img = ax.imshow(layer_data[name], cmap=colormaps.get(name, \"viridis\"), extent=[xmin, xmax, ymin, ymax], origin='upper')\n",
    "        ax.set_title(name)\n",
    "        ax.set_xlabel(\"Longitude\")\n",
    "        ax.set_ylabel(\"Latitude\")\n",
    "\n",
    "        xticks = np.linspace(xmin, xmax, 5)\n",
    "        yticks = np.linspace(ymin, ymax, 5)\n",
    "        ax.set_xticks(xticks)\n",
    "        ax.set_yticks(yticks)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=8)\n",
    "\n",
    "        fig.colorbar(img, ax=ax, fraction=0.046, pad=0.04)\n",
    "    else:\n",
    "        ax.axis('off')\n",
    "        print(f\"{name} missing for 2020\")\n",
    "\n",
    "for ax in axes[len(layers_to_plot):]:\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45eb20a1",
   "metadata": {},
   "source": [
    "Stacking all the raster data into a single multi-band raster and ensuring they are within the AOI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be77495",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_stack_by_year = {}\n",
    "\n",
    "# Extract static layers (DEM and Slope) once\n",
    "static_layers = {}\n",
    "for name in [\"DEM\", \"Slope\"]:\n",
    "    static_arr = cropped_rasters_by_year[2025].get(name)  # Any year works since they're static\n",
    "    if static_arr is not None:\n",
    "        static_layers[name] = static_arr\n",
    "    else:\n",
    "        print(f\"Static layer '{name}' not found in cropped data.\")\n",
    "\n",
    "# Stack temporal + static layers per year\n",
    "for year in range(2015, 2026):\n",
    "    year_data = cropped_rasters_by_year.get(year, {})\n",
    "    layers, layer_names = [], []\n",
    "\n",
    "    # Temporal layers (year-specific)\n",
    "    temporal_names = [\"LST\", \"NDWI\", \"NDVI_SD\", \"NDVI_range\", \"VV\", \"VH\"]\n",
    "    for name in temporal_names:\n",
    "        arr = year_data.get(name)\n",
    "        if arr is not None:\n",
    "            layers.append(arr)\n",
    "            layer_names.append(name)\n",
    "\n",
    "    # Add static layers\n",
    "    for name, arr in static_layers.items():\n",
    "        if arr is not None:\n",
    "            layers.append(arr)\n",
    "            layer_names.append(name)\n",
    "\n",
    "    # Check for consistent shapes and stack\n",
    "    if len(layers) >= 2 and len(set(arr.shape for arr in layers)) == 1:\n",
    "        feature_stack_by_year[year] = {\n",
    "            \"stack\": np.stack(layers, axis=-1),\n",
    "            \"layer_names\": layer_names\n",
    "        }\n",
    "    else:\n",
    "        print(f\"Year {year}: Missing or mismatched layers, skipped.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4983ac",
   "metadata": {},
   "source": [
    "extracting pixel values at the training points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68535103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cropped transform once from DEM using extent\n",
    "with rasterio.open(dem_path) as src:\n",
    "    window = from_bounds(*extent, transform=src.transform)\n",
    "    cropped_transform = src.window_transform(window)\n",
    "\n",
    "# Prepare coords\n",
    "coords = [(geom.x, geom.y) for geom in gdf.geometry]\n",
    "\n",
    "if 'training_data_by_year' not in globals():\n",
    "    training_data_by_year = {}\n",
    "\n",
    "for year in feature_stack_by_year:\n",
    "    feature_stack = feature_stack_by_year[year]['stack']\n",
    "    transform = cropped_transform  # fixed for all years since cropping extent is same\n",
    "\n",
    "    rows_cols = [rowcol(transform, x, y) for x, y in coords]\n",
    "\n",
    "    pixels, labels = [], []\n",
    "    for (row, col), label in zip(rows_cols, gdf[\"class\"]):\n",
    "        if 0 <= row < feature_stack.shape[0] and 0 <= col < feature_stack.shape[1]:\n",
    "            px = feature_stack[row, col, :]\n",
    "            if not np.any(np.isnan(px)):\n",
    "                pixels.append(px)\n",
    "                labels.append(label)\n",
    "\n",
    "    X = np.array(pixels)\n",
    "    y = np.array(labels)\n",
    "    le = LabelEncoder()\n",
    "    y_encoded = le.fit_transform(y)\n",
    "    training_data_by_year[year] = {\"X\": X, \"y\": y_encoded, \"label_encoder\": le}\n",
    "\n",
    "    print(f\"Year {year}: {len(y)} samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b2289e",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2020\n",
    "df_samples = pd.DataFrame(training_data_by_year[year]['X'], columns=layer_names)\n",
    "df_samples['class'] = training_data_by_year[year]['y']\n",
    "df_samples.iloc[:-10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6a4949",
   "metadata": {},
   "source": [
    "#### 4.3 Stratified 5-fold Cross validation with Random Forest  \n",
    "Training the random forest model using the training dataset \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2c1e74",
   "metadata": {},
   "source": [
    "Combined Train/Test and Cross validation training of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167ac561",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_per_year(year, training_data, test_size=0.2, n_estimators_cv=100, n_estimators_final=200, random_state=42):\n",
    "    \"\"\"\n",
    "    Train Random Forest model for each year with train/test split and cross-validation.\n",
    "    \n",
    "    Returns:\n",
    "        model: final trained model on combined train+val\n",
    "        metrics: dict with CV and test accuracies and predictions\n",
    "    \"\"\"\n",
    "    data = training_data[year]\n",
    "    X, y, le = data[\"X\"], data[\"y\"], data[\"label_encoder\"]\n",
    "\n",
    "    # Split into train+val and test sets\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, stratify=y, random_state=random_state\n",
    "    )\n",
    "\n",
    "    # Cross-validation training\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "    cv_true, cv_pred = [], []\n",
    "    for train_idx, val_idx in skf.split(X_train_val, y_train_val):\n",
    "        rf = RandomForestClassifier(n_estimators=n_estimators_cv, random_state=random_state)\n",
    "        rf.fit(X_train_val[train_idx], y_train_val[train_idx])\n",
    "        y_val_pred = rf.predict(X_train_val[val_idx])\n",
    "        cv_true.extend(y_train_val[val_idx])\n",
    "        cv_pred.extend(y_val_pred)\n",
    "\n",
    "    cv_accuracy = accuracy_score(cv_true, cv_pred)\n",
    "\n",
    "    # Final model on combined train+val\n",
    "    final_rf = RandomForestClassifier(n_estimators=n_estimators_final, random_state=random_state)\n",
    "    final_rf.fit(X_train_val, y_train_val)\n",
    "\n",
    "    # Test set evaluation\n",
    "    y_test_pred = final_rf.predict(X_test)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "    metrics = {\n",
    "        \"cv_true\": cv_true,\n",
    "        \"cv_pred\": cv_pred,\n",
    "        \"cv_accuracy\": cv_accuracy,\n",
    "        \"y_test\": y_test,\n",
    "        \"y_test_pred\": y_test_pred,\n",
    "        \"test_accuracy\": test_accuracy,\n",
    "        \"label_encoder\": le,\n",
    "    }\n",
    "\n",
    "    return final_rf, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b72e7f",
   "metadata": {},
   "source": [
    "#### 4.4 Prediction   \n",
    "Prediction of the wetland classess based on the model and estimation of area covered by each class in Ha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880418f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model for a specific year\n",
    "def prediction_per_year(year, model, feature_stack_by_year, extent, label_encoder):\n",
    "    \"\"\"\n",
    "    Predict classification raster for one year and compute area per class.\n",
    "    \n",
    "    Returns:\n",
    "        pred_img: 2D numpy array of predictions with -1 outside AOI\n",
    "        class_areas: dict of class names to area in hectares\n",
    "    \"\"\"\n",
    "    feature_stack = feature_stack_by_year[year][\"stack\"]\n",
    "    flat = feature_stack.reshape(-1, feature_stack.shape[-1])\n",
    "    valid_mask = ~np.isnan(flat).any(axis=1)\n",
    "\n",
    "    pred = np.full(flat.shape[0], -1, dtype=int)\n",
    "    pred[valid_mask] = model.predict(flat[valid_mask])\n",
    "    pred_img = pred.reshape(feature_stack.shape[:2])\n",
    "    #pred_img[~aoi_mask] = -1\n",
    "\n",
    "    counts = Counter(pred_img[pred_img >= 0])\n",
    "\n",
    "    # Calculate pixel area in hectares\n",
    "    lat = (extent[1] + extent[3]) / 2\n",
    "    deg_to_m = 111320  # meters per degree\n",
    "    pixel_w = abs(extent[2] - extent[0]) / pred_img.shape[1]\n",
    "    pixel_h = abs(extent[3] - extent[1]) / pred_img.shape[0]\n",
    "    pixel_area_ha = (pixel_w * deg_to_m * math.cos(math.radians(lat))) * (pixel_h * deg_to_m) / 10_000\n",
    "\n",
    "    class_areas = {\n",
    "        label_encoder.inverse_transform([cls])[0]: count * pixel_area_ha for cls, count in counts.items()\n",
    "    }\n",
    "\n",
    "    return pred_img, class_areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f480736",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_by_year = {}\n",
    "metrics_by_year = {}\n",
    "predictions_by_year = {}\n",
    "\n",
    "for year in sorted(training_data_by_year.keys()):\n",
    "    print(f\"\\nProcessing year {year}...\")\n",
    "\n",
    "    # Train model\n",
    "    model, metrics = train_model_per_year(year, training_data_by_year)\n",
    "    models_by_year[year] = model\n",
    "    metrics_by_year[year] = metrics\n",
    "\n",
    "    print(f\"Year {year} CV Accuracy: {metrics['cv_accuracy']:.4f}\")\n",
    "    print(f\"Year {year} Test Accuracy: {metrics['test_accuracy']:.4f}\")\n",
    "\n",
    "    # Predict\n",
    "    pred_img, class_areas = prediction_per_year(year, model, feature_stack_by_year, extent, metrics[\"label_encoder\"])\n",
    "    predictions_by_year[year] = {\n",
    "        \"pred_img\": pred_img,\n",
    "        \"class_areas\": class_areas,\n",
    "    }\n",
    "\n",
    "    print(f\"Prediction complete for year {year}.\")                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c63b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2020\n",
    "le = metrics_by_year[year]['label_encoder']\n",
    "labels = le.classes_\n",
    "pred_img = predictions_by_year[year]['pred_img']\n",
    "y_test = metrics_by_year[year]['y_test']\n",
    "y_test_pred = metrics_by_year[year]['y_test_pred']\n",
    "\n",
    "# Check metrics\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_test_pred, target_names=le.classes_))\n",
    "\n",
    "# Show predicted class areas\n",
    "print(f\"Estimated area per class for year {year}:\")\n",
    "for cls, area in predictions_by_year[year]['class_areas'].items():\n",
    "    print(f\"  {cls}: {area:.2f} ha\")\n",
    "\n",
    "# Plot the prediction map for that year\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "\n",
    "cmap = ListedColormap(['#145a32', '#abb2b9', '#3498db', '#f39c12'][:len(labels)])\n",
    "norm = BoundaryNorm(np.arange(len(labels)+1)-0.5, cmap.N)\n",
    "\n",
    "plot_img = np.ma.masked_where(pred_img < 0, pred_img)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "im = plt.imshow(plot_img, cmap=cmap, norm=norm, extent=extent, origin='upper')\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "plt.title(f\"Classification Prediction for {year}\")\n",
    "plt.gca().set_aspect('equal')\n",
    "cbar = plt.colorbar(im, ticks=np.arange(len(labels)))\n",
    "cbar.ax.set_yticklabels(labels)\n",
    "cbar.set_label(\"Class\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7964a8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "\n",
    "def plot_lat_lon_ticks(ax, transform, n_ticks=6):\n",
    "    height, width = ax.get_images()[0].get_array().shape\n",
    "\n",
    "    # Calculate tick positions in pixel coordinates\n",
    "    x_ticks_px = np.linspace(0, width - 1, n_ticks).astype(int)\n",
    "    y_ticks_px = np.linspace(0, height - 1, n_ticks).astype(int)\n",
    "\n",
    "    # Convert pixel coords to lat/lon using transform, extracting scalars properly\n",
    "    x_ticks = [(transform * (x, 0))[0] for x in x_ticks_px]\n",
    "    y_ticks = [(transform * (0, y))[1] for y in y_ticks_px]\n",
    "\n",
    "    ax.set_xticks(x_ticks_px)\n",
    "    ax.set_xticklabels([f\"{val:.2f}\" for val in x_ticks])\n",
    "    ax.set_yticks(y_ticks_px)\n",
    "    ax.set_yticklabels([f\"{val:.2f}\" for val in y_ticks])\n",
    "\n",
    "    ax.set_xlabel(\"Longitude\")\n",
    "    ax.set_ylabel(\"Latitude\")\n",
    "\n",
    "# Your plotting code:\n",
    "year = 2020\n",
    "le = metrics_by_year[year]['label_encoder']\n",
    "labels = le.classes_\n",
    "pred_img = predictions_by_year[year]['pred_img']\n",
    "extent = (xmin, xmax, ymin, ymax)\n",
    "cmap = ListedColormap(['#145a32', '#abb2b9', '#3498db', '#f39c12'][:len(labels)])\n",
    "norm = BoundaryNorm(np.arange(len(labels) + 1) - 0.5, cmap.N)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "im = ax.imshow(pred_img, cmap=cmap, norm=norm, extent=extent, origin='upper')\n",
    "\n",
    "cbar = plt.colorbar(im, ax=ax, ticks=np.arange(len(labels)))\n",
    "cbar.ax.set_yticklabels(labels)\n",
    "cbar.set_label(\"Class\")\n",
    "\n",
    "plot_lat_lon_ticks(ax, cropped_transform, n_ticks=6)  # Use your actual cropped transform here\n",
    "\n",
    "ax.set_title(f\"Classification Prediction for {year}\")\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zfl_wetland",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
